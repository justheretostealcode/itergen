{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78299456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Desktop/coding/SDT/updated_itergen/itergen/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alex/Desktop/coding/SDT/updated_itergen/itergen/itergen/syncode/syncode/evaluation/fol_eval.py:259: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  NOTE: since nltk does not support reg strs like \\w+, we cannot separately recognize VAR, PRED, and CONST.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Downloading shards: 100%|██████████| 2/2 [01:09<00:00, 34.83s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.53s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DFA mask store for LlamaTokenizerFast and custom, may take more than 10 minutes. Caching at /home/alex/Desktop/coding/SDT/updated_itergen/itergen/cache/mask_stores/LlamaTokenizerFast/grammar_strict_1698613057_32000.pkl.\n",
      "Ignore whitespace tokens is True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:03<00:00,  5.13it/s]\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: [', in a small town nestled in the heart of the countryside, there lived a young girl named Lily. She was a curious and adventurous child, always eager to explore the world around her. One']\n",
      "Current Words: [[', ', 'in ', 'a ', 'small ', 'town ', 'nestled ', 'in ', 'the ', 'heart ', 'of ', 'the ', 'countryside', ', ', 'there ', 'lived ', 'a ', 'young ', 'girl ', 'named ', 'Lily', 'She ', 'was ', 'a ', 'curious ', 'and ', 'adventurous ', 'child', ', ', 'always ', 'eager ', 'to ', 'explore ', 'the ', 'world']]\n"
     ]
    }
   ],
   "source": [
    "from itergen.main import IterGen\n",
    "\n",
    "# Define the grammar\n",
    "grammar = \"\"\"\n",
    "start: paragraph\n",
    "paragraph: sentence+\n",
    "sentence: word+ sentence_end\n",
    "word: /[a-zA-Z0-9]+/ | other_punctuations\n",
    "sentence_end: \".\" | \"!\" | \"?\"\n",
    "other_punctuations: \",\" | \";\" | \":\" | \"'\"\n",
    "%ignore \" \"\n",
    "\"\"\"\n",
    "\n",
    "# Initialize IterGen with the grammar and a model with Hugging Face model ID\n",
    "iter_gen = IterGen(grammar=grammar, model_id=\"microsoft/Phi-3-mini-128k-instruct\", max_tokens=50)\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# Start generation\n",
    "iter_gen.start(prompt)\n",
    "\n",
    "# Generate one sentence\n",
    "generated_sentence = iter_gen.forward(stop_symbol=\"sentence\", num=1)\n",
    "print(\"Generated Sentence:\", generated_sentence)\n",
    "\n",
    "# Backtrack by 2 words\n",
    "iter_gen.backward(\"word\", num=2)\n",
    "\n",
    "# Inspect all words in the current generation\n",
    "current_words = iter_gen.view(\"word\")\n",
    "print(\"Current Words:\", current_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
